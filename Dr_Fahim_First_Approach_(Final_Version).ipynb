{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arashfahim/Deep-Schemes-for-Control/blob/main/Dr_Fahim_First_Approach_(Final_Version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPXG1OIOocCx"
      },
      "source": [
        "# Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KC9LVSRd81e",
        "outputId": "4cad9489-69ae-4ee6-e50e-c6874d7fac5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive,files\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoRmv9NiS4nZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "from scipy import misc\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR, CyclicLR, ReduceLROnPlateau, LinearLR, ExponentialLR\n",
        "import random\n",
        "from torch.autograd.functional import jacobian, hessian\n",
        "# import AUTOGRAD.FUNCTIONAL.JACOBIAN as jacobian\n",
        "import time\n",
        "import math\n",
        "\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rcParams['legend.fontsize'] = 10\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djnS8fgCiWnV"
      },
      "source": [
        "#$n=1 \\quad (d=2)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0Gl_iCSiWNO"
      },
      "outputs": [],
      "source": [
        "# dim=2\n",
        "# kappa=torch.tensor([1]).to(device)\n",
        "# theta=torch.tensor([0.4]).to(device)\n",
        "# nu=torch.tensor([0.02]).to(device)\n",
        "# lamb=torch.tensor([0.15]).to(device)\n",
        "# eta=torch.tensor([0.5]).to(device)\n",
        "# rho=torch.tensor([0.0]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpXPObUtUeXw"
      },
      "source": [
        "#$n=2 \\quad (d=3)$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpCjilgZiBY9"
      },
      "outputs": [],
      "source": [
        "# dim=3\n",
        "# kappa=torch.tensor([1,0.8]).to(device)\n",
        "# theta=torch.tensor([0.1,0.2]).to(device)\n",
        "# nu=torch.tensor([0.02,0.015]).to(device)\n",
        "# lamb=torch.tensor([0.15,0.11]).to(device)\n",
        "# eta=torch.tensor([1]).to(device)\n",
        "# rho=torch.tensor([0.0,0.0]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiRwEoebWHb6"
      },
      "source": [
        "#$n=4 \\quad (d=5)$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHMkWTLkXVj7"
      },
      "outputs": [],
      "source": [
        "# dim=5\n",
        "# kappa=torch.tensor([1,0.8,0.6,0.4]).to(device)\n",
        "# theta=torch.tensor([0.1,0.2,0.3,0.4]).to(device)\n",
        "# nu=torch.tensor([0.02,0.015,0.11,0.12]).to(device)\n",
        "# lamb=torch.tensor([0.15,0.11,0.12,0.13]).to(device)\n",
        "# eta=torch.tensor([1]).to(device)\n",
        "# rho=torch.tensor([0.0,0.0,0.0,0.0]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO4jngRpDYko"
      },
      "source": [
        "#$n=9 \\quad (d=10)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJvun6xqDgM3"
      },
      "outputs": [],
      "source": [
        "dim=10\n",
        "kappa=torch.tensor([1,0.8,0.6,0.4,0.5,0.3,0.2,0.1,0.7]).to(device)\n",
        "theta=torch.tensor([0.1,0.2,0.3,0.4,0.5,0.4,0.3,0.2,0.1]).to(device)\n",
        "nu=torch.tensor([0.02,0.015,0.11,0.12,0.01,0.013,0.14,0.14,0.01]).to(device)\n",
        "lamb=torch.tensor([0.15,0.11,0.12,0.13,0.15,0.11,0.12,0.13,0.15]).to(device)\n",
        "eta=torch.tensor([1]).to(device)\n",
        "rho=torch.tensor([0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GApRNhvAFC8B"
      },
      "outputs": [],
      "source": [
        "# print(num_sample)\n",
        "# print(num_sample/2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYTV5FY_ol3m"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCjiUfN0oiF9"
      },
      "outputs": [],
      "source": [
        "num_sample=2**15   #M\n",
        "#dim=5\n",
        "num_time_interval=20    #N\n",
        "T=torch.tensor([1]).to(device)\n",
        "delta_t = torch.tensor(T/ num_time_interval)\n",
        "# t_steps = torch.linspace(0,1,num_time_interval).to(device)\n",
        "# sqrt_delta_t = torch.sqrt(delta_t).to(device)\n",
        "sqrt_delta_t = torch.sqrt(delta_t).to(device)\n",
        "x_init = torch.zeros(dim)\n",
        "# sigma=torch.sqrt(torch.tensor([2.0]))\n",
        "# lamb=torch.tensor([1.0]).to(device)\n",
        "mu=torch.tensor([1.0]).to(device)\n",
        "# sigma=torch.tensor([1.0]).to(device)\n",
        "alpha=torch.tensor([1.0]).to(device)\n",
        "start = torch.tensor([0]).to(device)\n",
        "end = torch.tensor([1]).to(device)\n",
        "num_steps=5\n",
        "num_ite=int(num_time_interval/num_steps)\n",
        "# kappa=torch.tensor([1]).to(device)\n",
        "# theta=torch.tensor([0.4]).to(device)\n",
        "# nu=torch.tensor([0.5]).to(device)\n",
        "# lamb=torch.tensor([0.6]).to(device)\n",
        "# eta=torch.tensor([0.5]).to(device)\n",
        "p=torch.tensor([0.95]).to(device)\n",
        "# rho=torch.tensor([0]).to(device)\n",
        "num_runs=1\n",
        "# x0=torch.ones([1,dim]).to(device)+4\n",
        "# print(x0)\n",
        "\n",
        "t_steps = torch.linspace(0,T.item(),num_time_interval+1).to(device)\n",
        "# print(t_steps)\n",
        "test_interval=[0.5,1.5]\n",
        "# v=(torch.ones(num_sample,dim,dim)-0.3).to(device)\n",
        "# v=(torch.ones(num_sample,dim,dim)).to(device)\n",
        "v=torch.diag(torch.ones(dim)).to(device)\n",
        "# print(v)\n",
        "v=v.unsqueeze(0).repeat(num_sample,1,1)\n",
        "print(v.shape)\n",
        "# print(v)\n",
        "\n",
        "\n",
        "# dt=T/num_time_interval\n",
        "Dt=torch.zeros((num_sample,1,num_time_interval+1)).to(device)\n",
        "print(Dt.shape)\n",
        "Dt[:,:,1:]=dt\n",
        "t=torch.cumsum(Dt,axis=2).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3feRG9_9PKl2"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTguvp5GPHkf"
      },
      "outputs": [],
      "source": [
        "def H(x,z,gamma): #### out_shape =([M]) |  input:  x_shape=[M,D,1],  z shape = [M,D,1],gamma shape= [M,dim,dim]\n",
        "  result=torch.zeros([x.shape[0]]).to(device)\n",
        "  for i in range(dim-1):\n",
        "    result+=kappa[i]*(theta[i]-x[:,i+1,0])*z[:,i+1,0]+0.5*torch.pow(nu[i],2)*gamma[:,i+1,i+1]-rho[i]*lamb[i]*nu[i]*(z[:,0,0]*gamma[:,0,i+1])/gamma[:,0,0] \\\n",
        "    + 0.5*torch.pow(rho[i]*nu[i]*gamma[:,0,i+1],2)/gamma[:,0,0]\n",
        "    # print(result)\n",
        "  result1=result-0.5*torch.sum(torch.square(lamb))*torch.pow(z[:,0,0],2)/gamma[:,0,0]\n",
        "  return result1\n",
        "\n",
        "\n",
        "def F(x,z,a): #### out_shape =([M]) |  input:  x_shape=[M,D,1],  z shape = [M,D,1],a_shape= [M,D,D]  #This is for rho=0\n",
        "  result=torch.zeros([x.shape[0]]).to(device)\n",
        "  for i in range(dim-1):\n",
        "    result+=-kappa[i]*(theta[i]-x[:,i+1,0])*z[:,i+1,0]\n",
        "    # print(result)\n",
        "  result1=result-torch.sqrt(torch.sum(torch.square(lamb)))*torch.abs(z[:,0,0])*torch.sqrt(a[:,0,0])\n",
        "  return result1\n",
        "\n",
        "\n",
        "def g1(x): #out_shape= [M,1,1]   | input:  x_shape=[M,D]\n",
        "  result=1-torch.exp(-eta*x[:,0])\n",
        "  # result=torch.reshape(result,(result.shape[0],1,1))\n",
        "  result=torch.reshape(result,(result.shape[0],1))\n",
        "  return result\n",
        "\n",
        "def update(data,delta_w,L):#output: data=(M,D,1) ,  #input data=(M,D,1), delta_w=[M,D,1]\n",
        "    dx = torch.bmm(L,delta_w)\n",
        "    data = data + dx\n",
        "    data=data\n",
        "    return data\n",
        "\n",
        "def der1(x,f):  #output= [M,D,1], input: x=[M,D,1]\n",
        "  Du=torch.zeros(x.shape[0],dim).to(device)\n",
        "  xin=x.clone().detach()\n",
        "  xin.requires_grad=True\n",
        "  # print('xin shape', xin.shape)\n",
        "  u=f(xin)\n",
        "  # print(u)\n",
        "  # print('u/f(xin) shape', u.shape)\n",
        "  Du=torch.autograd.grad(outputs=[u],inputs=[xin],grad_outputs=torch.ones_like(u),\n",
        "                          allow_unused=True,retain_graph=True,create_graph=True)[0].unsqueeze(2)\n",
        "  # print('Du shape before reshaped', Du.shape)\n",
        "  Du=torch.reshape(Du,(Du.shape[0],dim,1))\n",
        "  # print('Du shape after reshaped', Du.shape)\n",
        "  return Du\n",
        "\n",
        "\n",
        "def grad_hessian1(t, x,f_): #output= [M,D,D], #input: x=[M,D], t=[M,1], xt= [M,D+1]\n",
        "    hess_temp=torch.zeros(x.shape[0],dim,dim).to(device)\n",
        "    Du=torch.zeros(x.shape[0],dim).to(device)\n",
        "\n",
        "    xin=x.clone().detach()\n",
        "    xin.requires_grad=True\n",
        "    # print(\"xin_shape\", xin.shape)\n",
        "    tin=t.clone().detach()\n",
        "    # print(\"tin shape\", tin.shape)\n",
        "    xt_in=torch.cat((xin,tin),1)\n",
        "    # print(\"xt_in shape\", xt_in.shape)\n",
        "\n",
        "\n",
        "\n",
        "    # xt_in.requires_grad=True\n",
        "    u=f_(xt_in)\n",
        "    # print(\"u shape: \",u.shape)\n",
        "    Du=torch.autograd.grad(outputs=[u],inputs=[xin],grad_outputs=torch.ones_like(u),\n",
        "                           allow_unused=True,retain_graph=True,create_graph=True)[0].unsqueeze(2)\n",
        "    # print(\"Du shape:\",Du.shape)\n",
        "    # print(\"-----\")\n",
        "    # print(torch.autograd.grad(outputs=[Du[:,0,:]],inputs=[xin],grad_outputs=torch.ones_like(Du[:,0,:]),\n",
        "    #                        allow_unused=True,retain_graph=True,create_graph=True)[0].shape)\n",
        "    hess_temp= torch.cat([ torch.autograd.grad(outputs=[Du[:,i,:]],inputs=[xin],grad_outputs=torch.ones_like(Du[:,i,:]),\n",
        "                           allow_unused=True,retain_graph=True,create_graph=True)[0] for i in range(dim)],1)\n",
        "    # print(\"D2u shape:\",hess_temp.shape)\n",
        "    Du = torch.reshape(Du,(Du.shape[0],dim,1))\n",
        "    # print(\"Du after reshape:\",Du.shape)\n",
        "    hess_temp=torch.reshape(hess_temp,(hess_temp.shape[0],dim,dim))\n",
        "    # print(\"D2u after reshape:\",hess_temp.shape)\n",
        "\n",
        "    # print(hess_temp)\n",
        "    return Du, hess_temp\n",
        "\n",
        "\n",
        "def grad_model(t, x,f_): #output= [M,D,1], #input: x=[M,D], t=[M,1], xt= [M,D+1]\n",
        "    hess_temp=torch.zeros(x.shape[0],dim,dim).to(device)\n",
        "    Du=torch.zeros(x.shape[0],dim).to(device)\n",
        "\n",
        "    xin=x.clone().detach()\n",
        "    xin.requires_grad=True\n",
        "    # print(\"xin_shape\", xin.shape)\n",
        "    tin=t.clone().detach()\n",
        "    # print(\"tin shape\", tin.shape)\n",
        "    xt_in=torch.cat((xin,tin),1)\n",
        "    # print(\"xt_in shape\", xt_in.shape)\n",
        "\n",
        "    # xt_in.requires_grad=True\n",
        "    u=f_(xt_in)\n",
        "    # print(\"u shape: \",u.shape)\n",
        "    Du=torch.autograd.grad(outputs=[u],inputs=[xin],grad_outputs=torch.ones_like(u),\n",
        "                           allow_unused=True,retain_graph=True,create_graph=True)[0].unsqueeze(2)\n",
        "\n",
        "    Du = torch.reshape(Du,(Du.shape[0],dim,1))\n",
        "    # print(\"Du after reshape:\",Du.shape)\n",
        "\n",
        "    return Du\n",
        "\n",
        "\n",
        "def hessian_model(t,x,model):\n",
        "    hess_temp=torch.zeros(x.shape[0],dim,dim).to(device)\n",
        "    Du=torch.zeros(x.shape[0],dim).to(device)\n",
        "\n",
        "    xin=x.clone().detach()\n",
        "    xin.requires_grad=True\n",
        "    # print(\"xin_shape\", xin.shape)\n",
        "    tin=t.clone().detach()\n",
        "    # print(\"tin shape\", tin.shape)\n",
        "    xt_in=torch.cat((xin,tin),1)\n",
        "    # print(\"xt_in shape\", xt_in.shape)\n",
        "    Du = model(xt_in)\n",
        "    hess_temp= torch.cat([ torch.autograd.grad(outputs=[Du[:,i]],inputs=[xin],grad_outputs=torch.ones_like(Du[:,i]),\n",
        "                           allow_unused=True,retain_graph=True,create_graph=True)[0] for i in range(dim)],1)\n",
        "\n",
        "    # print(\"D2u shape:\",hess_temp.shape)\n",
        "\n",
        "    hess_temp=torch.reshape(hess_temp,(hess_temp.shape[0],dim,dim))\n",
        "\n",
        "    # print(hess_temp)\n",
        "    return hess_temp\n",
        "\n",
        "\n",
        "\n",
        "def hessian1(x,model2z):  #x=[M,D,1]  output= [M,D,1]\n",
        "    hess_temp=torch.zeros(x.shape[0],dim,dim).to(device)\n",
        "    # print(\"D2u shape:\",hess_temp.shape)\n",
        "\n",
        "    Du=torch.zeros(x.shape[0],dim).to(device)\n",
        "    xin=x.clone().detach()\n",
        "    # print('this is xin')\n",
        "    # print(xin)\n",
        "    xin.requires_grad=True\n",
        "    Du = model2z(xin.squeeze(2))\n",
        "    # print('this is Du')\n",
        "    # print(Du)\n",
        "    # print('this is Du shape')\n",
        "    # print(Du.shape)\n",
        "    # print('this is Du 1')\n",
        "    # print(Du[:,1,:])\n",
        "    hess_temp= torch.cat([ torch.autograd.grad(outputs=[Du[:,i,:]],inputs=[xin],grad_outputs=torch.ones_like(Du[:,i,:]),\n",
        "                           allow_unused=True,retain_graph=True,create_graph=True)[0] for i in range(dim)],1)\n",
        "\n",
        "    # print(\"D2u shape:\",hess_temp.shape)\n",
        "\n",
        "    hess_temp=torch.reshape(hess_temp,(hess_temp.shape[0],dim,dim))\n",
        "\n",
        "    # print(hess_temp)\n",
        "    return hess_temp\n",
        "\n",
        "\n",
        "def grad_fn2(x,z,a,f,xx=False,r=False,p=False,alpha=False):  #output= [M,D,1], input: x=[M,D,1] z=[M,D,1], a=[M,D,D]\n",
        "  Du=torch.zeros(x.shape[0],dim).to(device)\n",
        "  xin=x.clone().detach()\n",
        "  xin.requires_grad=True\n",
        "  # print('xin shape', xin.shape)\n",
        "  zin=z.clone().detach()\n",
        "  zin.requires_grad=True\n",
        "  # print('zin shape', zin.shape)\n",
        "  ain=a.clone().detach()\n",
        "  ain.requires_grad=True\n",
        "  # print('ain shape', ain.shape)\n",
        "  # ain=torch.reshape(ain,(num_sample,dim*dim,1))\n",
        "  u=f(xin,zin,ain)\n",
        "  # print(u)\n",
        "  # print('u/f(xin) shape', u.shape)\n",
        "  if xx==True:\n",
        "    Du=torch.autograd.grad(outputs=[u],inputs=[xin],grad_outputs=torch.ones_like(u),\n",
        "                            allow_unused=True,retain_graph=True,create_graph=True)[0]\n",
        "    # print('Du shape before reshaped', Du.shape)\n",
        "    Du=torch.reshape(Du,(Du.shape[0],dim,1))\n",
        "    # print('Du shape after reshaped', Du.shape)\n",
        "  if r==True:\n",
        "    Du=torch.autograd.grad(outputs=[u],inputs=[rin],grad_outputs=torch.ones_like(u),\n",
        "                            allow_unused=True,retain_graph=True,create_graph=True)[0]\n",
        "    # print('Du shape before reshaped', Du.shape)\n",
        "    Du=torch.reshape(Du,(Du.shape[0],1,1))\n",
        "    # Du=torch.reshape(Du,(Du.shape[0],dim,dim))\n",
        "    # print('Du shape after reshaped', Du.shape)\n",
        "  if p==True:\n",
        "    Du=torch.autograd.grad(outputs=[u],inputs=[zin],grad_outputs=torch.ones_like(u),\n",
        "                            allow_unused=True,retain_graph=True,create_graph=True)[0]\n",
        "    # print('Du shape before reshaped', Du.shape)\n",
        "    Du=torch.reshape(Du,(Du.shape[0],dim,1))\n",
        "    # print('Du shape after reshaped', Du.shape)\n",
        "  if alpha==True:\n",
        "    Du=torch.autograd.grad(outputs=[u],inputs=[ain],grad_outputs=torch.ones_like(u),\n",
        "                            allow_unused=True,retain_graph=True,create_graph=True)[0]\n",
        "    # print('Du shape before reshaped', Du.shape)\n",
        "    Du=torch.reshape(Du,(Du.shape[0],dim,dim))\n",
        "    # print('Du shape after reshaped', Du.shape)\n",
        "\n",
        "  return Du\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def L_matrix(ite,x,model):  #x=[M,D]\n",
        "  L=torch.zeros(x.shape[0],dim,dim)\n",
        "\n",
        "  L[:,0,0]=model[ite](x)\n",
        "  for i in range(dim-1):\n",
        "    L[:,i+1,i+1]=nu[i]\n",
        "  return L\n",
        "def opt_quad():\n",
        "  return torch.pow(torch.sum(torch.pow(lamb,2)),0.5)/eta\n",
        "\n",
        "# def L_matrix_test(ite,x,model1):  #This matrix is a matrix with L00 = 0.6 and L11=nu\n",
        "#   L=torch.zeros(x.shape[0],dim,dim)\n",
        "#   L[:,0,0]=opt_quad()\n",
        "#   for i in range(dim-1):\n",
        "#     L[:,i+1,i+1]=nu[i]\n",
        "#   return L\n",
        "\n",
        "def L_matrix_test(x):  #This matrix is a matrix with L00 = 0.6 and L11=nu\n",
        "  L=torch.zeros(x.shape[0],dim,dim)\n",
        "  L[:,0,0]=opt_quad()\n",
        "  for i in range(dim-1):\n",
        "    L[:,i+1,i+1]=nu[i]\n",
        "  return L\n",
        "\n",
        "def V1(t,x,v):\n",
        "  # result=(1-torch.exp(-eta*x))*(torch.exp(-0.5*(T-t)*torch.sum(torch.pow(lamb,2))))\n",
        "  result=-torch.exp(-eta*x-0.5*(T-t)*torch.sum(torch.pow(lamb,2))).to(device)\n",
        "  return result\n",
        "\n",
        "def V(t,x,v): #output           |#input:\n",
        "  result=1-torch.exp(-eta*x-0.5*(T-t)*torch.sum(torch.pow(lamb,2))).to(device)\n",
        "  return result\n",
        "\n",
        "\n",
        "def V1(t,x,v):\n",
        "  # result=(1-torch.exp(-eta*x))*(torch.exp(-0.5*(T-t)*torch.sum(torch.pow(lamb,2))))\n",
        "  result=-torch.exp(-eta*x-0.5*(T-t)*torch.sum(torch.pow(lamb,2))).to(device)\n",
        "  return result\n",
        "\n",
        "def derV(t,x,v): #output           |#input:\n",
        "  result=eta*torch.exp(-eta*x-0.5*(T-t)*torch.sum(torch.pow(lamb,2))).to(device)\n",
        "  return result\n",
        "\n",
        "def hessianV(t,x,v): #output           |#input:\n",
        "  result=-torch.pow(eta,2)*torch.exp(-eta*x-0.5*(T-t)*torch.sum(torch.pow(lamb,2))).to(device)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ghJ8nEDHJNR"
      },
      "outputs": [],
      "source": [
        "# x_test=torch.ones(2,dim,1).float().to(device)\n",
        "# z_test=torch.ones(2,dim,1).float().to(device)\n",
        "# a_test=torch.ones(2,dim,dim).float().to(device)\n",
        "# derivative_alpha=grad_fn2(x_test,z_test,a_test,F,alpha=True)\n",
        "# print(derivative_alpha)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwlWGpcaJM9W"
      },
      "outputs": [],
      "source": [
        "# derivative_z=grad_fn2(x_test,z_test,a_test,F,p=True)\n",
        "# print(derivative_z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTE1iu7AK190"
      },
      "outputs": [],
      "source": [
        "# print(kappa)\n",
        "# print(lamb)\n",
        "# print(-lamb/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS1VrR_lKU3Q"
      },
      "outputs": [],
      "source": [
        "# a_test.requires_grad_()\n",
        "# u=F(x_test,z_test,a_test)\n",
        "# gd =torch.autograd.grad(outputs=u[0],inputs=a_test,retain_graph=True,create_graph=True)[0]\n",
        "# print(gd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gra6P00NvTb"
      },
      "outputs": [],
      "source": [
        "# delta=0.00001\n",
        "# with torch.no_grad():\n",
        "#   u1=F(x_test,z_test,a_test)\n",
        "#   u2=F(x_test,z_test,a_test+delta)\n",
        "# print((u2-u1)/delta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZJPkCbmrqMg",
        "outputId": "d72262b8-5ec9-42eb-d73b-fd7a4969e921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3928])\n"
          ]
        }
      ],
      "source": [
        "print(opt_quad())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYXwp5vnwGVG"
      },
      "source": [
        "## T Generator Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvUpziu6vMxj"
      },
      "outputs": [],
      "source": [
        "def t_generator(size):\n",
        "  Dt=torch.zeros((size,1,num_time_interval+1)).to(device)\n",
        "  Dt[:,:,1:]=dt\n",
        "  t=torch.cumsum(Dt,axis=2).to(device)\n",
        "  return t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwaEs7jLwOhN"
      },
      "source": [
        "## Plot Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7omk-r96mm3P"
      },
      "outputs": [],
      "source": [
        "def plot(start,end,steps, t_test, ite,model,modely=False, modelz=False,modelv=False):\n",
        "  xs = torch.linspace(start, end, steps=steps)\n",
        "  # print(xs)\n",
        "  ys = torch.linspace(start,end, steps=steps)\n",
        "  # print(ys)\n",
        "  xgrid, ygrid = torch.meshgrid(xs, ys, indexing='xy')\n",
        "  # print(xgrid)\n",
        "#  print(xgrid.shape)\n",
        "  # print(ygrid)\n",
        "  # print(xgrid.flatten().shape)\n",
        "  sss=torch.stack((xgrid.flatten(),ygrid.flatten()),1).to(device)\n",
        "  # print(sss)\n",
        "  # print(sss.shape)\n",
        "\n",
        "  t=t_generator(steps*steps)\n",
        "  sss_t=torch.cat((sss,t[:,:,t_test]),1)\n",
        "  # print(sss_t)\n",
        "\n",
        "  if modelz==True:\n",
        "    z=model(sss_t).clone().detach().cpu()\n",
        "    # print(z.shape)\n",
        "    z=torch.reshape(z,(steps,steps))\n",
        "    fig = plt.figure(figsize=plt.figaspect(0.5))\n",
        "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
        "    # ax=plt.axes(projection='3d')\n",
        "    ax.plot_surface(xgrid.numpy(), ygrid.numpy(), z.numpy(),label = \"trained_modelY\")\n",
        "\n",
        "\n",
        "    truez = derV(t_steps[t_test],xgrid.to(device),ygrid.to(device)).clone().detach().cpu()\n",
        "    # print(\"This is theoretical solution\")\n",
        "    # print(truey)\n",
        "    true_matrixz=torch.reshape(truez,(steps,steps))\n",
        "    # print(true_matrix.shape)\n",
        "    # ax = plt.axes(projection='3d')\n",
        "    ax.plot_surface(xgrid.numpy(), ygrid.numpy(), true_matrixy.numpy(),label = \"True\")\n",
        "\n",
        "    ax.set_title(\"MSE of the trained model Y at timestep {}: {:.7f}\".format(t_test,np.mean(np.square(true_matrixz.numpy()-z.numpy()))))\n",
        "    ax.set_xlabel(r'x', fontsize=15, rotation=70)\n",
        "    ax.set_ylabel(r'v', fontsize=15, rotation=60)\n",
        "    plt.show()\n",
        "  if modelv==True:\n",
        "    z1=model[ite](sss_t).clone().detach().cpu()\n",
        "    # print(z.shape)\n",
        "    z1=torch.reshape(z1,(steps,steps))\n",
        "    fig = plt.figure(figsize=plt.figaspect(0.5))\n",
        "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
        "    # ax=plt.axes(projection='3d')\n",
        "    ax.plot_surface(xgrid.numpy(), ygrid.numpy(), z1.numpy(),label = \"trained_modelV\")\n",
        "\n",
        "\n",
        "    trueV = torch.zeros(steps,steps)\n",
        "\n",
        "    # true_matrixV=torch.reshape(truey,(steps,steps))\n",
        "    # print(true_matrix.shape)\n",
        "    # ax = plt.axes(projection='3d')\n",
        "    ax.plot_surface(xgrid.numpy(), ygrid.numpy(), trueV.numpy(),label = \"True\")\n",
        "\n",
        "    ax.set_title(\"MSE of the trained model V at timestep {}: {:.7f}\".format(t_test,np.mean(np.square(trueV.numpy()-z1.numpy()))))\n",
        "    ax.set_xlabel(r'x', fontsize=15, rotation=70)\n",
        "    ax.set_ylabel(r'v', fontsize=15, rotation=60)\n",
        "    plt.show()\n",
        "  if modely==True:\n",
        "    z=model(sss_t).clone().detach().cpu()\n",
        "    # print(z.shape)\n",
        "    z=torch.reshape(z,(steps,steps))\n",
        "    fig = plt.figure(figsize=plt.figaspect(0.5))\n",
        "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
        "    # ax=plt.axes(projection='3d')\n",
        "    ax.plot_surface(xgrid.numpy(), ygrid.numpy(), z.numpy(),label = \"trained_modelY\")\n",
        "\n",
        "\n",
        "    truey = V(t_steps[t_test],xgrid.to(device),ygrid.to(device)).clone().detach().cpu()\n",
        "    # print(\"This is theoretical solution\")\n",
        "    # print(truey)\n",
        "    true_matrixy=torch.reshape(truey,(steps,steps))\n",
        "    # print(true_matrix.shape)\n",
        "    # ax = plt.axes(projection='3d')\n",
        "    ax.plot_surface(xgrid.numpy(), ygrid.numpy(), true_matrixy.numpy(),label = \"True\")\n",
        "\n",
        "    ax.set_title(\"MSE of the trained model Y at timestep {}: {:.7f}\".format(t_test,np.mean(np.square(true_matrixy.numpy()-z.numpy()))))\n",
        "    ax.set_xlabel(r'x', fontsize=15, rotation=70)\n",
        "    ax.set_ylabel(r'v', fontsize=15, rotation=60)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoxWnBIto_RG"
      },
      "source": [
        "## Mean Error Funcion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFnrmLBvdv_4"
      },
      "outputs": [],
      "source": [
        "size=1000\n",
        "test_samples=[(test_interval[0]+(test_interval[1]-test_interval[0])*torch.rand(size).to(device)) for i in range(dim)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBjF8tH1pBQn"
      },
      "outputs": [],
      "source": [
        "def mean_error(test_samples,start,end,t_test, ite,model,modely=False, modelz=False,modelv=False):\n",
        "  # test_samples=[(start+(end-start)*torch.rand(size).to(device)) for i in range(dim)]\n",
        "  sss = torch.stack(test_samples,dim=1)\n",
        "  t=t_generator(size)\n",
        "  sss_t=torch.cat((sss,t[:,:,t_test]),1)\n",
        "\n",
        "\n",
        "  # print(sss_t.shape)\n",
        "\n",
        "  # if modelz==True:\n",
        "\n",
        "  #   z=model(sss_t).clone().detach().cpu()\n",
        "  #   truez = derV(t_steps[t_test],xgrid.to(device),ygrid.to(device)).clone().detach().cpu()\n",
        "\n",
        "  #   print(\"MSE of the trained model Y at timestep {}: {:.7f}\".format(t_test,np.mean(np.square(z-truez))))\n",
        "\n",
        "\n",
        "  # if modelv==True:\n",
        "  #   z1=model[ite](sss_t).clone().detach().cpu()\n",
        "\n",
        "\n",
        "    # trueV = torch.zeros(steps,steps)\n",
        "\n",
        "\n",
        "    # print(\"MSE of the trained model V at timestep {}: {:.7f}\".format(t_test,np.mean(np.square(trueV.numpy()-z1.numpy()))))\n",
        "\n",
        "  if modely==True:\n",
        "    z2=model(sss_t).clone().detach().cpu()\n",
        "    # print(z2.shape)\n",
        "    truey = V(t_test,sss_t[:,0],sss_t[:,1:]).clone().detach().cpu()\n",
        "    # print(truey.shape)\n",
        "\n",
        "    # print(\"MSE of the trained model Y at timestep {}: {:.7f}\".format(t_test,np.mean(np.square(truey.numpy()-z2.numpy()))))\n",
        "    error=[np.mean(np.absolute(truey.numpy()-z2.numpy())/truey.numpy()),np.mean(np.square(truey.numpy()-z2.numpy()))]\n",
        "    return error\n",
        "    # return np.mean(np.absolute(truey.numpy()-z2.numpy())/z2.numpy()),np.mean(np.square(truey.numpy()-z2.numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otIZej9N2Qpv",
        "outputId": "7843c7da-f4b3-4305-d211-afc0a66884f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "x=np.array(3-4)\n",
        "print(np.absolute(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTR6jiM9A8eb"
      },
      "outputs": [],
      "source": [
        "  # t=t_generator(3*3)\n",
        "  # print(t.shape)\n",
        "  # print(t[:,:,20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-Ow0hh3_2w4"
      },
      "outputs": [],
      "source": [
        "def grad_mean(start,end,steps,model,s):\n",
        "  xs = torch.linspace(start, end, steps=steps)\n",
        "  ys = torch.linspace(start,end, steps=steps)\n",
        "\n",
        "  xgrid, ygrid = torch.meshgrid(xs, ys, indexing='xy')\n",
        "  sss=torch.stack((xgrid.flatten(),ygrid.flatten()),1).to(device)\n",
        "  t=t_generator(steps*steps)\n",
        "  accum_mean=0\n",
        "  # sss_t=torch.cat((sss,t[:,:,20]),1)\n",
        "  # print(torch.mean(torch.mean(model[s](sss_t))))\n",
        "  for i in range(0,num_time_interval+1):\n",
        "    sss_t=torch.cat((sss,t[:,:,i]),1)\n",
        "    # print(model[s](sss_t).shape)\n",
        "    accum_mean+=torch.mean(torch.abs(model[s](sss_t)))\n",
        "  return accum_mean/num_time_interval\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6T03RNGBOYy"
      },
      "outputs": [],
      "source": [
        "# mean1=grad_mean(test_interval[0],test_interval[1],100,modelV,0)\n",
        "# print(mean1)\n",
        "# mean2=grad_mean(test_interval[0],test_interval[1],100,loaded_model_V_new,0)\n",
        "# print(mean2)\n",
        "\n",
        "#Two Criterions:  Less Than Thresshold or Difference between s and s+1 less than a threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amNWTJBFPPpt",
        "outputId": "83cd9fda-0537-4bbe-d85e-0cd0c2083a7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3928])\n"
          ]
        }
      ],
      "source": [
        "print(opt_quad())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkOz0tC-CAv5"
      },
      "outputs": [],
      "source": [
        "def gradient(x,f): #input=  [M,D,1]    #output= [M,D,1]\n",
        "  xin=x.clone().detach()\n",
        "  xin.requires_grad=True\n",
        "  u=f(xin.squeeze(2));\n",
        "  Du=torch.autograd.grad(outputs=[u],inputs=[xin],grad_outputs=torch.ones_like(u),allow_unused=True,retain_graph=True,create_graph=True)[0]\n",
        "  return Du"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ZHHU-S79jN"
      },
      "source": [
        "# Initilizing Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CemjVNb5VKma"
      },
      "outputs": [],
      "source": [
        "class ann(nn.Module): #input [M,D+1]   #output [M,1]\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ann, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(dim+1, 128),\n",
        "            nn.BatchNorm1d(num_features=128),\n",
        "            # nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.BatchNorm1d(num_features=128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128,128),\n",
        "            nn.BatchNorm1d(num_features=128),\n",
        "            nn.Tanh(),\n",
        "            # nn.Linear(128, 128),\n",
        "            # nn.BatchNorm1d(num_features=128),\n",
        "            # nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.Tanh(),\n",
        "            nn.Linear(128,1),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpYkel-i-qG1"
      },
      "outputs": [],
      "source": [
        "class annz(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(annz, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(dim+1, 128),\n",
        "            nn.BatchNorm1d(num_features=128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128,128),\n",
        "            nn.BatchNorm1d(num_features=128),\n",
        "            nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.Tanh(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(num_features=64),\n",
        "            nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.Tanh(),\n",
        "            nn.Linear(64,dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJAo5jk6vyPg"
      },
      "outputs": [],
      "source": [
        "class annsigma(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(annsigma, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(dim+1, 128),\n",
        "            nn.BatchNorm1d(num_features=128),\n",
        "            nn.Tanh(),\n",
        "            # nn.Linear(256,128),\n",
        "            # nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.Tanh(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.BatchNorm1d(num_features=128),\n",
        "            nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.Tanh(),\n",
        "            # nn.Linear(128,128),\n",
        "            # nn.Tanh(),\n",
        "            nn.Linear(128,128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128,dim*dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        # print(logits.shape)\n",
        "        logits=torch.reshape(logits,(-1,dim,dim))\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAfE1sPow8KY",
        "outputId": "cfebf244-e12d-4fec-ae09-3ebd0664a383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        }
      ],
      "source": [
        "print(dim*dim*num_time_interval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Gi4uTeXVrzA"
      },
      "outputs": [],
      "source": [
        "# num_max_ite=30\n",
        "modelY=ann().to(device)\n",
        "modelZ=annz().to(device)\n",
        "# modelV= nn.ModuleList([ann() for i in range(num_max_ite+1)]).to(device)\n",
        "# modelderV= nn.ModuleList([annz() for i in range(num_max_ite+1)]).to(device)\n",
        "\n",
        "\n",
        "modelV= ann().to(device)\n",
        "modelderV= annz().to(device)\n",
        "# modelsigma=ann().to(device)\n",
        "# temp=modelZ.copy()\n",
        "\n",
        "# copy.deepcopy()\n",
        "# temp=copy.deepcopy(modelZ)\n",
        "# aa=torch.rand(num_sample,dim+1).to(device)\n",
        "# print(modelZ(aa))\n",
        "# print(temp(aa))\n",
        "modelsigma=annsigma().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPouEpKjwRyo"
      },
      "outputs": [],
      "source": [
        "# print(modelsigma(aa).shape)\n",
        "# print(modelsigma(aa)[:,:,1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7joeGhWx-uh"
      },
      "outputs": [],
      "source": [
        "# print(sigma_init[:,:,:,1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjuBipfjJtpi"
      },
      "source": [
        "#Sigma_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMpGjmb1gLRH",
        "outputId": "9b0868a0-e9ae-4181-e9cf-cd6cd3aaaf0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32768, 10, 10, 20])\n"
          ]
        }
      ],
      "source": [
        "sigma_init=torch.zeros(num_sample,dim,dim,num_time_interval).to(device)\n",
        "x_sample = torch.zeros([num_sample,dim, num_time_interval + 1]).to(device)\n",
        "for i in range(num_time_interval):\n",
        "  sigma_init[:,:,:,i]=L_matrix_test(x_sample)+torch.diag(torch.ones(dim))\n",
        "  # sigma_init[:,:,:,i]=L_matrix_test(x_sample)\n",
        "  # sigma_init[:,:,:,i]=L_matrix_test(x_sample)\n",
        "  # sigma_init[:,:,:,i]=sigma_init[:,:,:,i]\n",
        "print(sigma_init.shape)\n",
        "xinit=torch.tensor([0]).to(device)\n",
        "# print(sigma_init[:,:,:,2])\n",
        "# print(sigma_init[:,:,:,2]**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cH4A60GMx07p"
      },
      "outputs": [],
      "source": [
        "# print((modelsigma(aa)[:,:,:,1]-sigma_init[:,:,:,1]).shape)\n",
        "# print(torch.mean(torch.square((modelsigma(aa)[:,:,:,1]-sigma_init[:,:,:,1]))).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_oHRt_6hxLv"
      },
      "source": [
        "# Update_Sigma Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_sigma(sigma_init,modelsigma):\n",
        "  for ite in range(0,num_time_interval):\n",
        "      xt=torch.cat((x_sample[:,:,ite],t[:,:,ite]),1).to(device)\n",
        "      sigma_init[:,:,:,ite]=modelsigma(xt)\n",
        "  return sigma_init"
      ],
      "metadata": {
        "id": "TgRsIIR1SHJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBy4OfBxh03o"
      },
      "outputs": [],
      "source": [
        "# def update_sigma(s,i,lr): #output:               | #input\n",
        "#   result=torch.zeros(num_sample, 1).to(device)\n",
        "#   xt=torch.cat((x_sample[:,:,i],t[:,:,i]),1).to(device)\n",
        "#   # print('this is xt shape', xt.shape)\n",
        "#   sigma=torch.randn(num_sample,dim,dim).to(device)\n",
        "#   # print(sigma)\n",
        "#   for j in range(s):\n",
        "#     result=result+modelV[j](xt)\n",
        "#   # print((v.reshape(num_sample,dim*dim)*result).reshape(num_sample,dim,dim))\n",
        "#   return sigma+lr*(v.reshape(num_sample,dim*dim)*result).reshape(num_sample,dim,dim)\n",
        "\n",
        "\n",
        "# def update_sigma(sigma,s,i,lr): #output:               | #input\n",
        "#   result=torch.zeros(num_sample, 1).to(device)\n",
        "#   xt=torch.cat((x_sample[:,:,i],t[:,:,i]),1).to(device)\n",
        "#   # print('this is xt shape', xt.shape)\n",
        "\n",
        "#   for j in range(s):\n",
        "#     result=result+modelV[j](xt)\n",
        "#   # print((v.reshape(num_sample,dim*dim)*result).reshape(num_sample,dim,dim))\n",
        "#   return sigma+lr*(v.reshape(num_sample,dim*dim)*result).reshape(num_sample,dim,dim)\n",
        "\n",
        "# def update_sigma(sigma_init,time_step,s,v,lr):\n",
        "#   result=sigma_init.clone()\n",
        "#   xt=torch.cat((x_sample[:,:,time_step],t[:,:,time_step]),1).to(device)\n",
        "#   for i in range(s):\n",
        "#     # print(modelV[i](xt))\n",
        "#     # print(modelV[i](xt).unsqueeze(2)*v)\n",
        "#     result[:,:,:,time_step]=result[:,:,:,time_step]+lr*(modelV[i](xt).unsqueeze(2)*v)\n",
        "#     # print(result[:,:,:,time_step])\n",
        "#   # print(result[:,:,:,time_step])\n",
        "#   return result[:,:,:,time_step]\n",
        "#   #   sigma_init[:,:,:,time_step]=sigma_init[:,:,:,time_step]+lr*(modelV[j](xt).unsqueeze(2)*v)\n",
        "#   # return sigma_init[:,:,:,time_step]\n",
        "# def update_sigma(sigma_init,time_step,s,v,lr):\n",
        "#   result=sigma_init.clone()\n",
        "#   if s==0:\n",
        "#     result[:,:,:,time_step]=sigma[:,:,:,time_step]\n",
        "#   else:\n",
        "#     xt=torch.cat((x_sample[:,:,time_step],t[:,:,time_step]),1).to(device)\n",
        "#     result[:,:,:,time_step]=result[:,:,:,time_step]+lr*(modelsigma(xt).unsqueeze(2)*v)\n",
        "#   return result[:,:,:,time_step]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mADr_KSoDEP"
      },
      "source": [
        "# Net Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q-XINT9Vz2h"
      },
      "outputs": [],
      "source": [
        "def net_u( x,t): #output:               | #input:  x=[M,D], t=[M,1]\n",
        "  Du=torch.zeros(x.shape[0],dim).to(device)\n",
        "  xin=x.clone().detach()\n",
        "  xin.requires_grad=True\n",
        "  # xin=x.clone().detach()\n",
        "  # tin=t.clone().detach()\n",
        "  # # print(xin)\n",
        "  # xin.requires_grad=True\n",
        "  # xcat=torch.cat((xin,tin),1)\n",
        "  xcat=torch.cat((xin,t),1)\n",
        "  # print(xcat.shape)\n",
        "  u=modelY(xcat).to(device)\n",
        "  # print(u.shape)\n",
        "  Du=torch.autograd.grad(outputs=[u],inputs=[xin],grad_outputs=torch.ones_like(u),allow_unused=True,retain_graph=True,create_graph=True)[0]\n",
        "  Du=torch.reshape(Du,(Du.shape[0],dim,1))\n",
        "  return u,Du\n",
        "\n",
        "\n",
        "def net_z( x,t): #output:               | #input:  x=[M,D], t=[M,1]\n",
        "  Du=torch.zeros(x.shape[0],dim).to(device)\n",
        "  xin=x.clone().detach()\n",
        "  xin.requires_grad=True\n",
        "  # xin=x.clone().detach()\n",
        "  # tin=t.clone().detach()\n",
        "  # # print(xin)\n",
        "  # xin.requires_grad=True\n",
        "  # xcat=torch.cat((xin,tin),1)\n",
        "  xcat=torch.cat((xin,t),1)\n",
        "  # print(xcat.shape)\n",
        "  z=modelZ(xcat).to(device)\n",
        "  # print(u.shape)\n",
        "\n",
        "  z=torch.reshape(z,(z.shape[0],dim,1))\n",
        "  return z\n",
        "def net_v(x,t): #output:               | #input:  x=[M,D], t=[M,1]\n",
        "  Du=torch.zeros(x.shape[0],dim).to(device)\n",
        "  xin=x.clone().detach()\n",
        "  xin.requires_grad=True\n",
        "  # xin=x.clone().detach()\n",
        "  # tin=t.clone().detach()\n",
        "  # # print(xin)\n",
        "  # xin.requires_grad=True\n",
        "  # xcat=torch.cat((xin,tin),1)\n",
        "  xcat=torch.cat((xin,t),1)\n",
        "  # print(xcat.shape)\n",
        "  u=modelV(xcat).to(device)\n",
        "  # print(u.shape)\n",
        "  Du=torch.autograd.grad(outputs=[u],inputs=[xin],grad_outputs=torch.ones_like(u),allow_unused=True,retain_graph=True,create_graph=True)[0]\n",
        "  Du=torch.reshape(Du,(Du.shape[0],dim,1))\n",
        "  return u,Du\n",
        "\n",
        "def derg(x):\n",
        "  x.requires_grad=True\n",
        "  u=g(x);\n",
        "  Du=torch.autograd.grad(outputs=[u],inputs=[x],grad_outputs=torch.ones_like(u),allow_unused=True,retain_graph=True,create_graph=True)[0]\n",
        "  return Du"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8tTe-SmfcKH"
      },
      "source": [
        "#Optimizer 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Va27pRammZKz"
      },
      "outputs": [],
      "source": [
        "def opt1(lr_,SGD=False, Adam=False):\n",
        "\n",
        "  if SGD==True:\n",
        "    # optimizer=optim.SGD(list(modelY.parameters())+list(modelZ.parameters()),lr=lr_,momentum=0.9)\n",
        "    optimizer=optim.SGD(list(modelY.parameters())+list(modelZ.parameters()),lr=lr_)\n",
        "  if Adam==True:\n",
        "    # optimizer=optim.Adam(modelV[s].parameters(),lr=lr_,weight_decay=1e-5)\n",
        "    optimizer=optim.Adam(list(modelY.parameters())+list(modelZ.parameters()),lr=lr_)\n",
        "# opt = SGD(lr=0.01, momentum=0.9)\n",
        "  # scheduler=ExponentialLR(optimizer,gamma=0.9)\n",
        "  return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEjSQtUiwZcV"
      },
      "source": [
        "#Loss Function 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e_9DB_twYqG"
      },
      "outputs": [],
      "source": [
        "def loss_fn1(x_sample,dw_sample,temp_index):\n",
        "    loss1=0\n",
        "    Y0,dY0=net_u(x_sample[temp_index,:,0],t[temp_index,:,0])\n",
        "    Z0=net_z(x_sample[temp_index,:,0],t[temp_index,:,0])\n",
        "    loss1=loss1+torch.mean(torch.mean(torch.square(dY0-Z0),1))\n",
        "    for ite in range(0,num_time_interval):\n",
        "      Y_pred=Y0+F(x_sample[temp_index,:,ite].unsqueeze(2),Z0,(sigma_init[temp_index,:,:,ite]**2)).unsqueeze(1)*delta_t+torch.bmm(torch.bmm(torch.transpose(Z0,1,2),sigma_init[temp_index,:,:,ite]),dw_sample[temp_index,:,ite].unsqueeze(2)).squeeze(2)\n",
        "      Y1,dY1=net_u(x_sample[temp_index,:,ite+1],t[temp_index,:,ite+1])\n",
        "      Z1=net_z(x_sample[temp_index,:,ite+1],t[temp_index,:,ite+1])\n",
        "      Y0=Y1\n",
        "      Z0=Z1\n",
        "      # print(Z1)\n",
        "      if ite==num_time_interval-1:\n",
        "        loss1=loss1+torch.mean(torch.square(Y_pred-g1(x_sample[temp_index,:,ite+1])))\n",
        "        loss1=loss1+torch.mean(torch.mean(torch.square(Z1-der1(x_sample[temp_index,:,ite+1],g1)),1))\n",
        "      if ite != num_time_interval-1:\n",
        "        loss1=loss1+torch.mean(torch.mean(torch.square(Y_pred-Y1),1))\n",
        "        loss1=loss1+torch.mean(torch.mean(torch.square(dY1-Z1),1))\n",
        "    return loss1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQJP10kgfi83"
      },
      "source": [
        "#Optimizer 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UEkVQnmULUA"
      },
      "outputs": [],
      "source": [
        "def opt2(lr_,SGD=False, Adam=False):\n",
        "\n",
        "  if SGD==True:\n",
        "    # optimizer=optim.SGD(modelV[s].parameters(),lr=lr_,momentum=0.9)\n",
        "    optimizer=optim.SGD(list(modelV.parameters())+list(modelderV.parameters()),lr=lr_, momentum=0.9)\n",
        "    # optimizer=optim.SGD(list(modelV[s].parameters())+list(modelderV[s].parameters()),lr=lr_)\n",
        "  if Adam==True:\n",
        "    # optimizer=optim.Adam(modelV[s].parameters(),lr=lr_,weight_decay=1e-5)\n",
        "    # optimizer=optim.Adam(modelV[s].parameters(),lr=lr_)\n",
        "    optimizer=optim.SGD(list(modelV.parameters())+list(modelderV.parameters()),lr=lr_)\n",
        "\n",
        "  # scheduler=ExponentialLR(optimizer,gamma=0.9)\n",
        "  return optimizer\n",
        "\n",
        "\n",
        "# def opt2(ite,t1,t2):\n",
        "#   l=[]\n",
        "#   lr_=lr2[ite]\n",
        "\n",
        "#   # for i in range(t1,t2+1):\n",
        "#   #   l+=list(modely2[i].parameters())+list(modelz2[i].parameters())\n",
        "\n",
        "#   # l=list(modely2[t1].parameters())\n",
        "#   for i in range(t1,t2+1):\n",
        "#     l+=list(modely2[i].parameters())\n",
        "#   # optimizer=optim.Adam(l,lr=0.005)\n",
        "#   optimizer=optim.SGD(l, lr=lr_, momentum=0.9)\n",
        "#   # optimizer = torch.optim.Adam(l, lr=lr_, weight_decay=1e-5)\n",
        "#   # scheduler = ExponentialLR(optimizer, gamma =0.9)\n",
        "#   return optimizer\n",
        "\n",
        "# def opt1(lr_,SGD=False, Adam=False):\n",
        "\n",
        "#   if SGD==True:\n",
        "#     optimizer=optim.SGD(list(modelY.parameters())+list(modelZ.parameters()),lr=lr_)\n",
        "#   if Adam==True:\n",
        "#     # optimizer=optim.Adam(modelV[s].parameters(),lr=lr_,weight_decay=1e-5)\n",
        "#     optimizer=optim.Adam(list(modelY.parameters())+list(modelZ.parameters()),lr=lr_)\n",
        "\n",
        "#   # scheduler=ExponentialLR(optimizer,gamma=0.9)\n",
        "#   return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vuznWVmwpGC"
      },
      "source": [
        "# Loss Function 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdKJokLFwuyl"
      },
      "outputs": [],
      "source": [
        "def loss_fn2(x_sample,dw_sample,temp_index):\n",
        "  loss2=0\n",
        "  V0,dV0=net_v(x_sample[temp_index,:,0],t[temp_index,:,0])\n",
        "  derV0=modelderV(torch.cat((x_sample[temp_index,:,0],t[temp_index,:,0]),1))\n",
        "  loss2=loss2+torch.mean(torch.mean(torch.square(dV0.squeeze(2)-derV0),1))\n",
        "\n",
        "  Z0=modelZ(torch.cat((t[temp_index,:,0],x_sample[temp_index,:,0]),1)).unsqueeze(2)\n",
        "  # print(Z0.shape)\n",
        "  # xcat=torch.cat((xin,t),1)\n",
        "\n",
        "\n",
        "  dZ0=hessian_model(t[temp_index,:,0],x_sample[temp_index,:,0],modelZ)\n",
        "  # print(dZ0.shape)\n",
        "  # Z0,dZ0=grad_hessian1(t[:,:,0],x_sample[:,:,0],modelY)\n",
        "\n",
        "  for ite in range(0,num_time_interval):\n",
        "    V_pred=V0.flatten() +\\\n",
        "    (-torch.sum(torch.bmm(torch.transpose(sigma_init[temp_index,:,:,ite],1,2),v[temp_index,:,:])*dZ0,(1,2))+\\\n",
        "    torch.sum(v[temp_index,:,:]*grad_fn2(x_sample[temp_index,:,ite].unsqueeze(2),Z0,sigma_init[temp_index,:,:,ite],F,alpha=True),(1,2))+ \\\n",
        "    torch.sum(grad_fn2(x_sample[temp_index,:,ite].unsqueeze(2),Z0,sigma_init[temp_index,:,:,ite],F,p=True)*dV0,(1,2)))*dt+\\\n",
        "    torch.sum(torch.bmm(torch.bmm(torch.transpose(dV0,1,2),sigma_init[temp_index,:,:,ite]),dw_sample[temp_index,:,ite].unsqueeze(2)),(1,2))\n",
        "\n",
        "    V1,dV1=net_v(x_sample[temp_index,:,ite+1],t[temp_index,:,ite+1])\n",
        "    # Z0,dZ0=grad_hessian1(t[:,:,ite+1],x_sample[:,:,ite+1],modelY)\n",
        "\n",
        "    Z0=modelZ(torch.cat((t[temp_index,:,ite+1],x_sample[temp_index,:,ite+1]),1)).unsqueeze(2)\n",
        "    dZ0=hessian_model(t[temp_index,:,ite+1],x_sample[temp_index,:,ite+1],modelZ)\n",
        "\n",
        "    derV1=modelderV(torch.cat((x_sample[temp_index,:,ite+1],t[temp_index,:,ite+1]),1))\n",
        "\n",
        "    V0=V1\n",
        "    dV0=dV1\n",
        "    if ite==num_time_interval-1:\n",
        "      loss2=loss2+torch.mean(torch.square(V_pred))\n",
        "      loss2=loss2+torch.mean(torch.mean(torch.square(derV1),1))\n",
        "      loss2=loss2+torch.mean(torch.mean(torch.square(dV1)))\n",
        "    else:\n",
        "      loss2=loss2+torch.mean(torch.mean(torch.square(V_pred-V1.flatten())))\n",
        "      loss2=loss2+torch.mean(torch.mean(torch.square(dV1.squeeze(2)-derV1),1))\n",
        "  return loss2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7PcB-uw0fsZ"
      },
      "source": [
        "# Optimizer 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrvpjwfv0cyH"
      },
      "outputs": [],
      "source": [
        "def opt3(lr_,SGD=False, Adam=False):\n",
        "\n",
        "  if SGD==True:\n",
        "    # optimizer=optim.SGD(list(modelY.parameters())+list(modelZ.parameters()),lr=lr_,momentum=0.9)\n",
        "    optimizer=optim.SGD(modelsigma.parameters(),lr=lr_)\n",
        "  if Adam==True:\n",
        "    # optimizer=optim.Adam(modelV[s].parameters(),lr=lr_,weight_decay=1e-5)\n",
        "    optimizer=optim.Adam(modelsigma.parameters(),lr=lr_)\n",
        "  return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBGPDFC8wvSN"
      },
      "source": [
        "# Los Function 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6tWfiqfwzNt"
      },
      "outputs": [],
      "source": [
        "def loss_fn3(x_sample,dw_sample,temp_index):\n",
        "  loss3=0\n",
        "  for ite in range(0,num_time_interval):\n",
        "    xt=torch.cat((x_sample[temp_index,:,ite],t[temp_index,:,ite]),1).to(device)\n",
        "    loss3+=torch.mean(torch.square(modelsigma(xt)-(sigma_init[temp_index,:,:,ite]+lr*(modelV(xt).unsqueeze(2)*v[temp_index,:,:]))))\n",
        "  return loss3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F9dOjtQhKnq"
      },
      "source": [
        "# Train Both Models (ModelY and ModelV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqRfyM2Vibqz",
        "outputId": "d32c1693-da17-4f89-87be-79a760f02df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'int'>\n"
          ]
        }
      ],
      "source": [
        "num_max_ite=30\n",
        "num_epoch_1=100\n",
        "num_epoch_2=100\n",
        "num_epoch_3=20\n",
        "# optimizer1=opt1(0.0005,Adam=True)\n",
        "# optimizer2=opt2(0,0.0005,Adam=True)\n",
        "lr1=0.001\n",
        "lr2=0.001\n",
        "lr3=0.001\n",
        "\n",
        "\n",
        "\n",
        "lr=0.05\n",
        "# batch_size=64*2*2\n",
        "batch_size=int(num_sample/16)\n",
        "# batch_size=int(num_sample)\n",
        "print(type(batch_size))\n",
        "num_runs=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho63vQz2kIDe"
      },
      "outputs": [],
      "source": [
        "index=0\n",
        "last_loss1 = 0\n",
        "last_loss2=0\n",
        "last_loss3=0\n",
        "loss_delta1 = 0\n",
        "loss_delta2=0\n",
        "loss_delta3=0\n",
        "loss_treshold1 = 0\n",
        "loss_treshold2=0\n",
        "loss_treshold3=0\n",
        "loss_tmp1=[]\n",
        "loss_tmp2=[]\n",
        "loss_tmp3=[]\n",
        "\n",
        "\n",
        "average_error=0\n",
        "average_std=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0_WoSeUd_j_"
      },
      "source": [
        "#Train both models with Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl1WKwA94iVf",
        "outputId": "752d633a-37a0-49f5-8a55-ba7215fe7192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------------------------------------------\n",
            "This is 1th run\n",
            "--------------------------------------------------------\n",
            "---This is iteration  1\n",
            "-----This is loop 1\n",
            "Loss function 1 at epoch 0 is 7.406970977783e+00  |  Loss delta: 7.406970977783203   |    Training time: 19.15881s\n",
            "Loss function 1 at epoch 20 is -1.171588897705e-02  |  Loss delta: 5.910789489746094   |    Training time: 18.19592s\n"
          ]
        }
      ],
      "source": [
        "# optimizer1=opt1(0.000001,SGD=True)\n",
        "model1results=[]\n",
        "for r in range(num_runs):\n",
        "    print('----------------------------------------------------------------------------------------------------------------------------------------')\n",
        "    print(\"This is {}th run\".format(r+1))\n",
        "    model1_mean_error_timestep0=[]\n",
        "    model1_mean_error_timestep5=[]\n",
        "    model1_mean_error_timestep10=[]\n",
        "    # model1_rel_error_timestep0=[]\n",
        "    # model1_rel_error_timestep5=[]\n",
        "    # model1_rel_error_timestep10=[]\n",
        "\n",
        "    modelY=ann().to(device)\n",
        "    modelZ=annz().to(device)\n",
        "    modelV= ann().to(device)\n",
        "    modelsigma=annsigma().to(device)\n",
        "    for i in range(num_max_ite+1):\n",
        "      if i!=0:\n",
        "        sigma_init=update_sigma(sigma_init,modelsigma)\n",
        "########################################### optimization #1 ##########################################################################\n",
        "      optimizer1=opt1(lr1,SGD=True)\n",
        "      losslist1=[]\n",
        "      print('--------------------------------------------------------')\n",
        "      print('---This is iteration ',i+1)\n",
        "      # modelY=ann().to(device)\n",
        "      # modelZ=annz().to(device)\n",
        "      dw_sample = torch.randn(size=[num_sample, dim, num_time_interval]).to(device)* sqrt_delta_t\n",
        "      x_sample = torch.zeros([num_sample,dim, num_time_interval + 1]).to(device)\n",
        "      x_sample[:, :, 0] = test_interval[0]+(test_interval[1]-test_interval[0])*(torch.rand(num_sample,dim))\n",
        "      my_index=torch.arange(x_sample.shape[0])\n",
        "      total_batch=int((x_sample.shape[0]/batch_size))\n",
        "\n",
        "\n",
        "      for j in range(num_time_interval):\n",
        "        x_sample[:, :, j + 1] = x_sample[:, :, j] + torch.bmm(sigma_init[:,:,:,j],dw_sample[:, :, j].unsqueeze(2)).squeeze(2)\n",
        "\n",
        "      print('-----This is loop 1')\n",
        "      for epoch in range(num_epoch_1):\n",
        "        t_1=time.time()\n",
        "        for batch in range(total_batch):\n",
        "            if batch==total_batch-1:\n",
        "                  temp_index=my_index[batch*batch_size : ]\n",
        "            else:\n",
        "                  temp_index=my_index[batch*batch_size : batch*batch_size + batch_size]\n",
        "            # print(len(temp_index))\n",
        "            # print(x_sample[temp_index,:,:].shape)\n",
        "            optimizer1.zero_grad()\n",
        "            loss1=loss_fn1(x_sample[:,:,:],dw_sample[:,:,:],temp_index)\n",
        "\n",
        "            # loss1=loss_fn1(ite,data.unsqueeze(2)[temp_index,:].to(device),delta_w[temp_index,:].unsqueeze(2).to(device),model1[ite-1])\n",
        "            loss1.backward(retain_graph=True)\n",
        "            optimizer1.step()\n",
        "        # losslist1.append(loss1.item())\n",
        "\n",
        "        loss_tmp1.append(loss1.item())\n",
        "        loss_delta1 = loss1.item() - last_loss1\n",
        "        last_loss1 = loss1.item()\n",
        "        if epoch %20 == 0:\n",
        "          # print(loss1)\n",
        "          print(\"Loss function 1 at epoch {:.0f} is {:.12e}  |  Loss delta: {}   |    Training time: {:.5f}s\".format(index*(num_epoch_1)+epoch, loss_delta1,loss1.item(), time.time()-t_1))\n",
        "      if dim==2:\n",
        "        # plot(test_interval[0],test_interval[1],100,15,0,modelY,modely=True)\n",
        "        # plot(test_interval[0],test_interval[1],100,12,0,modelY,modely=True)\n",
        "        # plot(test_interval[0],test_interval[1],100,10,0,modelY,modely=True)\n",
        "        plot(test_interval[0],test_interval[1],100,7,0,modelY,modely=True)\n",
        "        plot(test_interval[0],test_interval[1],100,3,0,modelY,modely=True)\n",
        "        plot(test_interval[0],test_interval[1],100,1,0,modelY,modely=True)\n",
        "        plot(test_interval[0],test_interval[1],100,0,0,modelY,modely=True)\n",
        "      # def mean_error(start,end,size, t_test, ite,model,modely=False, modelz=False,modelv=False):\n",
        "      else:\n",
        "        model1_mean_error_timestep0.append(mean_error(test_samples,test_interval[0],test_interval[1],0,0,modelY,modely=True))\n",
        "        print(mean_error(test_samples,test_interval[0],test_interval[1],0,0,modelY,modely=True))\n",
        "        # print(model1_mean_error_timestep0)\n",
        "        # print(\"Relative Error Percent of the trained model Y at timestep {}: {:.7f}\".format(0, mean_error(test_samples,test_interval[0],test_interval[1],0,0,modelY,modely=True)[0]))\n",
        "        # print(\"MSE of the trained model Y at timestep {}: {:.7f}\".format(0, mean_error(test_samples,test_interval[0],test_interval[1],0,0,modelY,modely=True)[1]))\n",
        "\n",
        "\n",
        "        model1_mean_error_timestep5.append(mean_error(test_samples,test_interval[0],test_interval[1],5,0,modelY,modely=True))\n",
        "        print(mean_error(test_samples,test_interval[0],test_interval[1],5,0,modelY,modely=True))\n",
        "        # print(model1_mean_error_timestep5)\n",
        "        # print(\"Relative Error Percent of the trained model Y at timestep {}: {:.7f}\".format(5, mean_error(test_samples,test_interval[0],test_interval[1],5,0,modelY,modely=True)[0]))\n",
        "        # print(\"MSE of the trained model Y at timestep {}: {:.7f}\".format(5, mean_error(test_samples,test_interval[0],test_interval[1],5,0,modelY,modely=True)[1]))\n",
        "\n",
        "\n",
        "        model1_mean_error_timestep10.append(mean_error(test_samples,test_interval[0],test_interval[1],7,0,modelY,modely=True))\n",
        "        print(mean_error(test_samples,test_interval[0],test_interval[1],7,0,modelY,modely=True))\n",
        "        # print(model1_mean_error_timestep10)\n",
        "        # print(\"Relative Error Percent of the trained model Y at timestep {}: {:.7f}\".format(10, mean_error(test_samples,test_interval[0],test_interval[1],10,0,modelY,modely=True)[0]))\n",
        "        # print(\"MSE of the trained model Y at timestep {}: {:.7f}\".format(10, mean_error(test_samples,test_interval[0],test_interval[1],10,0,modelY,modely=True)[1]))\n",
        "########################################### optimization #2 ##########################################################################\n",
        "      optimizer2=opt2(lr2,SGD=True)\n",
        "      print('-----This is loop 2')\n",
        "      for epoch in range(num_epoch_2):\n",
        "        t_2=time.time()\n",
        "        for batch in range(total_batch):\n",
        "            if batch==total_batch-1:\n",
        "                  temp_index=my_index[batch*batch_size : ]\n",
        "            else:\n",
        "                  temp_index=my_index[batch*batch_size : batch*batch_size + batch_size]\n",
        "\n",
        "            optimizer2.zero_grad()\n",
        "            loss2=loss_fn1(x_sample[:,:,:],dw_sample[:,:,:],temp_index)\n",
        "\n",
        "            # loss1=loss_fn1(ite,data.unsqueeze(2)[temp_index,:].to(device),delta_w[temp_index,:].unsqueeze(2).to(device),model1[ite-1])\n",
        "            loss2.backward(retain_graph=True)\n",
        "            optimizer2.step()\n",
        "        # losslist2.append(loss2.item())\n",
        "        loss_tmp2.append(loss1.item())\n",
        "        loss_delta2 = loss1.item() - last_loss2\n",
        "        last_loss2 = loss2.item()\n",
        "        if epoch %20 == 0:\n",
        "          # print(loss1)\n",
        "          print(\"Loss function 2 at epoch {:.0f} is {:.12e}  |  Loss delta: {}   |    Training time: {:.5f}s\".format(index*(num_epoch_2)+epoch, loss_delta2,loss2.item(), time.time()-t_2))\n",
        "        if epoch %20 == 0:\n",
        "          print(loss2)\n",
        "########################################### optimization #3 ##########################################################################\n",
        "      optimizer3=opt3(lr3,SGD=True)\n",
        "      # losslist3=[]\n",
        "      print('-----This is loop 3')\n",
        "      for epoch in range(num_epoch_3):\n",
        "        t_3=time.time()\n",
        "        for batch in range(total_batch):\n",
        "            if batch==total_batch-1:\n",
        "                  temp_index=my_index[batch*batch_size : ]\n",
        "            else:\n",
        "                  temp_index=my_index[batch*batch_size : batch*batch_size + batch_size]\n",
        "\n",
        "            optimizer3.zero_grad()\n",
        "            loss3=loss_fn3(x_sample[:,:,:],dw_sample[:,:,:],temp_index)\n",
        "\n",
        "            # loss1=loss_fn1(ite,data.unsqueeze(2)[temp_index,:].to(device),delta_w[temp_index,:].unsqueeze(2).to(device),model1[ite-1])\n",
        "            loss3.backward(retain_graph=True)\n",
        "            optimizer3.step()\n",
        "        # losslist3.append(loss3.item())\n",
        "        loss_tmp3.append(loss3.item())\n",
        "        loss_delta3 = loss3.item() - last_loss3\n",
        "        last_loss3 = loss3.item()\n",
        "        if epoch %20 == 0:\n",
        "          # print(loss3)\n",
        "          print(\"Loss function 3 at epoch {:.0f} is {:.12e}  |  Loss delta: {}   |    Training time: {:.5f}s\".format(index*(num_epoch_3)+epoch, loss_delta3,loss3.item(), time.time()-t_3))\n",
        "      index+=1\n",
        "\n",
        "      if i==num_max_ite:\n",
        "        model1results.append(mean_error(test_samples,test_interval[0],test_interval[1],0,0,modelY,modely=True))\n",
        "        print(model1results)\n",
        "\n",
        "average_MSE=torch.mean(torch.tensor(model1results))\n",
        "average_std_MSE=torch.std(torch.tensor(model1results))\n",
        "\n",
        "print(\"The average MSE of {} independent runs of model1 at time step {} is {}\".format(num_runs,0,average_MSE))\n",
        "print(\"The average std MSE of {} independent runs of model1 at time step {} is {}\".format(num_runs,0,average_std_MSE))\n",
        "\n",
        "# print(\"The relative erorr percent of {} independent runs of model1 at time step {} is {}\".format(num_runs,0,relative_error_percent))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7egrSjlEKOj"
      },
      "source": [
        "#SAVE (PATH + CHECK POINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQATx1xuEHdO"
      },
      "outputs": [],
      "source": [
        "PATH = \"/content/gdrive//My Drive/universial_dim({})_num_sample({})_num_runs({})_num_epoch1({})_learning_rate1({})_learning_rate2({})_learning_rate3({})_batchsize({}).pt\".format(dim,num_sample,num_runs,num_epoch_1,lr1,lr2,lr3,batch_size)\n",
        "torch.save({\n",
        "            'epoch1': num_epoch_1,\n",
        "            'epoch2': num_epoch_2,\n",
        "            'epoch3': num_epoch_3,\n",
        "            'model_state_dict1': modelY.state_dict(),\n",
        "            'model_state_dict2': modelZ.state_dict(),\n",
        "            'model_state_dict3': modelsigma.state_dict(),\n",
        "            'optimizer_state_dict1': optimizer1.state_dict(),\n",
        "            'optimizer_state_dict2': optimizer2.state_dict(),\n",
        "            'optimizer_state_dict3': optimizer3.state_dict(),\n",
        "            # 'loss1':loss1.item(),\n",
        "            # 'loss2': loss2.item(),\n",
        "            'loss1_array': loss_tmp1,\n",
        "            'loss2_array': loss_tmp2,\n",
        "            'loss3_array': loss_tmp3,\n",
        "            'MSE_t0':model1_mean_error_timestep0,\n",
        "            'MSE_t5':model1_mean_error_timestep5,\n",
        "            'MSE_t10':model1_mean_error_timestep10,\n",
        "            # 'avg_rel_error': relative_error_percent,\n",
        "            'avg_MSE': average_MSE,\n",
        "            'avg_std': average_std_MSE,\n",
        "            }, PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(PATH)"
      ],
      "metadata": {
        "id": "5pkIDxrlSZ71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8lNyVaaPD6k"
      },
      "source": [
        "# LOAD (PATH + CHECK POINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sjc4wn2cEH2L"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(PATH)\n",
        "loaded_model1=ann().to(device)\n",
        "loaded_model1.load_state_dict(checkpoint['model_state_dict1'])\n",
        "loaded_model2=annz().to(device)\n",
        "loaded_model2.load_state_dict(checkpoint['model_state_dict2'])\n",
        "loaded_model3=annsigma().to(device)\n",
        "loaded_model3.load_state_dict(checkpoint['model_state_dict3'])\n",
        "\n",
        "loaded_optimizer1=opt1(1,SGD=True)\n",
        "loaded_optimizer1.load_state_dict(checkpoint['optimizer_state_dict1'])\n",
        "\n",
        "loaded_optimizer2=opt2(1,SGD=True)\n",
        "loaded_optimizer2.load_state_dict(checkpoint['optimizer_state_dict2'])\n",
        "\n",
        "\n",
        "loaded_optimizer3=opt1(1,SGD=True)\n",
        "loaded_optimizer3.load_state_dict(checkpoint['optimizer_state_dict1'])\n",
        "\n",
        "\n",
        "\n",
        "epoch1 = checkpoint['epoch1']\n",
        "# loss1 = checkpoint['loss1']\n",
        "epoch2 = checkpoint['epoch2']\n",
        "# loss2 = checkpoint['loss2']\n",
        "\n",
        "epoch3 = checkpoint['epoch3']\n",
        "# loss2 = checkpoint['loss2']\n",
        "\n",
        "loss1_array = checkpoint['loss1_array']\n",
        "loss2_array = checkpoint['loss2_array']\n",
        "loss3_array = checkpoint['loss3_array']\n",
        "\n",
        "\n",
        "\n",
        "MSE_t0=checkpoint['MSE_t0']\n",
        "MSE_t5=checkpoint['MSE_t5']\n",
        "MSE_t10=checkpoint['MSE_t10']\n",
        "\n",
        "\n",
        "# rel_error_percent=checkpoint['avg_rel_error']\n",
        "avg_MSE=checkpoint['avg_MSE']\n",
        "avg_std=checkpoint['avg_std']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG7EHTgqfgg2"
      },
      "source": [
        "## CHECK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdEz3qrVfVuw"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.array(MSE_t0))\n",
        "plt.xlabel('Number of Iterations (sigma updates)')\n",
        "plt.xticks(range(1,20))\n",
        "plt.ylabel('Mean Square Error')\n",
        "plt.title('At time step t={}'.format(0))\n",
        "plt.show"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}